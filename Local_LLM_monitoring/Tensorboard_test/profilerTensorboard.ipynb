{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe1d8c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Load pre-trained BERT\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device).eval()\n",
    "\n",
    "# Dummy input\n",
    "inputs = tokenizer(\"The quick brown fox jumps over the lazy dog\", return_tensors=\"pt\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4bf22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5db93f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir=\"./runs/bert_activation_debug\")\n",
    "activation_stats = {}\n",
    "\n",
    "global_step = 0  # will be updated in loop\n",
    "\n",
    "def make_hook(name):\n",
    "    def hook(module, input, output):\n",
    "        global global_step\n",
    "        if isinstance(output, torch.Tensor):\n",
    "            act_mean = output.mean().item()\n",
    "            buffer_size = output.nelement() * output.element_size()  # in bytes\n",
    "            writer.add_scalar(f\"{name}/activation_mean\", act_mean, global_step)\n",
    "            writer.add_scalar(f\"{name}/buffer_bytes\", buffer_size, global_step)\n",
    "    return hook\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e945df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Linear):\n",
    "        module.register_forward_hook(make_hook(name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36c4e2a",
   "metadata": {},
   "source": [
    "def register_hooks(model):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (torch.nn.Linear, torch.nn.Embedding, torch.nn.LayerNorm, torch.nn.Dropout, torch.nn.Conv1d)):\n",
    "            module.register_forward_hook(activation_hook)\n",
    "\n",
    "register_hooks(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7dcceceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(**inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c20245f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5787163424: {'layer': 'Embedding',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5804061520: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825224128: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.003072,\n",
      "              'output_shape': [1, 768]},\n",
      " 5825224944: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825225280: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825225760: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825226144: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825226912: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825227392: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825227440: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825228352: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825228880: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825229456: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825229792: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.135168,\n",
      "              'output_shape': [1, 11, 3072]},\n",
      " 5825230800: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825230896: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.135168,\n",
      "              'output_shape': [1, 11, 3072]},\n",
      " 5825231472: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825232048: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825577040: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825577136: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825577472: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.135168,\n",
      "              'output_shape': [1, 11, 3072]},\n",
      " 5825577616: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825577760: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825577856: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825577904: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825578000: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825578240: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825578432: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825578672: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.135168,\n",
      "              'output_shape': [1, 11, 3072]},\n",
      " 5825578768: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825578816: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825578864: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825578912: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825578960: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825579008: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825579344: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825579488: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825579632: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825579680: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825579728: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825579872: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825579920: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825579968: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825580112: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.135168,\n",
      "              'output_shape': [1, 11, 3072]},\n",
      " 5825580208: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825580400: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825580448: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825580496: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825580688: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825580736: {'layer': 'Embedding',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825580976: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825581120: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825581216: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825582128: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825582176: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825582272: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825582320: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825582368: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825582464: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825582608: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.135168,\n",
      "              'output_shape': [1, 11, 3072]},\n",
      " 5825582752: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825583616: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825583952: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825584000: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825584096: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.135168,\n",
      "              'output_shape': [1, 11, 3072]},\n",
      " 5825584192: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825584336: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825584432: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825584576: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825584864: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825584960: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825585104: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825585584: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.135168,\n",
      "              'output_shape': [1, 11, 3072]},\n",
      " 5825586352: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825586592: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825587312: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825587888: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825588176: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825588224: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825588320: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825588368: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825588512: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825588752: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825589232: {'layer': 'Embedding',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825589424: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825589520: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825589760: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825589856: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825589952: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.135168,\n",
      "              'output_shape': [1, 11, 3072]},\n",
      " 5825590000: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825590048: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825590144: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825590192: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825590240: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825590384: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825590432: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825590528: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825590576: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.135168,\n",
      "              'output_shape': [1, 11, 3072]},\n",
      " 5825590768: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825590960: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825591008: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825591056: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.135168,\n",
      "              'output_shape': [1, 11, 3072]},\n",
      " 5825591200: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825591248: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825591296: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825591392: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825591440: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825591488: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825591584: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825591872: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825591920: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825592112: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825592160: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825592208: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825592256: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825592448: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825592496: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825592544: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825592640: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.135168,\n",
      "              'output_shape': [1, 11, 3072]},\n",
      " 5825592784: {'layer': 'Dropout',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825592832: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825592880: {'layer': 'LayerNorm',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825593120: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825593216: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825593264: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]},\n",
      " 5825593312: {'layer': 'Linear',\n",
      "              'output_memory_MB': 0.033792,\n",
      "              'output_shape': [1, 11, 768]}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(activation_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2f3edf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if you're on Metal backend\n",
    "print(torch.backends.mps.is_available())  # True = running on M1/M2/M3 GPU\n",
    "\n",
    "# After model/input is loaded\n",
    "print(torch.mps.current_allocated_memory())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea9fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88eabfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "Running on device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vassilylombard/GITHUB_PALO-IT/LAB-VASSILY/venv312/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/vassilylombard/GITHUB_PALO-IT/LAB-VASSILY/venv312/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 0] Allocated: 48.21 MB, Reserved:  MB\n",
      "[Step 1] Allocated: 48.21 MB, Reserved:  MB\n",
      "[Step 2] Allocated: 48.21 MB, Reserved:  MB\n",
      "[Step 3] Allocated: 48.21 MB, Reserved:  MB\n",
      "[Step 4] Allocated: 48.21 MB, Reserved:  MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "# Enable MPS backend\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(f\"Running on device: {device}\")\n",
    "\n",
    "# Use a simple model for demo\n",
    "model = models.resnet18(pretrained=False).to(device).eval()\n",
    "\n",
    "# Dummy input\n",
    "input_tensor = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "# TensorBoard writer\n",
    "writer = SummaryWriter(log_dir=\"./runs/mps_memory_demo\")\n",
    "\n",
    "# Hook to log activation memory\n",
    "activation_stats = {}\n",
    "\n",
    "def activation_hook(module, input, output):\n",
    "    name = module.__class__.__name__\n",
    "    layer_id = id(module)\n",
    "    if hasattr(output, 'nelement'):\n",
    "        mem_mb = output.element_size() * output.nelement() / 1e6\n",
    "        activation_stats[layer_id] = {\n",
    "            \"layer\": name,\n",
    "            \"output_shape\": list(output.shape),\n",
    "            \"output_memory_MB\": mem_mb\n",
    "        }\n",
    "        writer.add_scalar(f\"LayerMemory/{name}_{layer_id}\", mem_mb)\n",
    "\n",
    "# Register hooks on linear & conv layers\n",
    "def register_hooks(model):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear, nn.ReLU)):\n",
    "            module.register_forward_hook(activation_hook)\n",
    "\n",
    "register_hooks(model)\n",
    "\n",
    "# Run a few passes and log MPS memory\n",
    "for step in range(5):\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "\n",
    "    # Log MPS GPU memory usage (in MB)\n",
    "    alloc_mem = torch.mps.current_allocated_memory() / 1e6\n",
    "    # reserved_mem = torch.mps.current_reserved_memory() / 1e6\n",
    "\n",
    "    print(f\"[Step {step}] Allocated: {alloc_mem:.2f} MB, Reserved:  MB\")\n",
    "    writer.add_scalar(\"MPS/AllocatedMemory_MB\", alloc_mem, step)\n",
    "    # writer.add_scalar(\"MPS/ReservedMemory_MB\", reserved_mem, step)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a44c179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "TensorBoard logging complete. Run `tensorboard --logdir=runs` to view.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "model_name = \"bert-base-uncased\"  # You can swap with \"gpt2\", etc.\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ========== LOAD MODEL ==========\n",
    "model = AutoModel.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# ========== TENSORBOARD WRITER ==========\n",
    "writer = SummaryWriter(log_dir=\"./runs/llm_monitor\")\n",
    "\n",
    "# ========== HOOK FUNCTION ==========\n",
    "global_step = 0\n",
    "\n",
    "def make_hook(name):\n",
    "    def hook(module, input, output):\n",
    "        global global_step\n",
    "        if isinstance(output, torch.Tensor):\n",
    "            act_mean = output.mean().item()\n",
    "            buffer_size = output.nelement() * output.element_size()\n",
    "            writer.add_scalar(f\"{name}/activation_mean\", act_mean, global_step)\n",
    "            writer.add_scalar(f\"{name}/buffer_bytes\", buffer_size, global_step)\n",
    "    return hook\n",
    "\n",
    "# ========== REGISTER HOOKS ==========\n",
    "for name, module in model.named_modules():\n",
    "    if \"encoder.layer\" in name and isinstance(module, torch.nn.Module):\n",
    "        module.register_forward_hook(make_hook(name))\n",
    "\n",
    "# ========== INFERENCE LOOP ==========\n",
    "sentences = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Large language models are powerful tools for AI.\",\n",
    "    \"Monitoring memory usage helps optimize performance.\",\n",
    "    \"PyTorch hooks allow introspection of hidden layers.\"\n",
    "]\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    global_step = i\n",
    "\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Log MPS memory stats\n",
    "    if device.type == \"mps\":\n",
    "        allocated = torch.mps.current_allocated_memory()\n",
    "        writer.add_scalar(\"MPS/AllocatedMemory\", allocated, global_step)\n",
    "\n",
    "    time.sleep(0.1)\n",
    "\n",
    "writer.close()\n",
    "print(\"TensorBoard logging complete. Run `tensorboard --logdir=runs` to view.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0ebf624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vassilylombard/GITHUB_PALO-IT/LAB-VASSILY/venv312/lib/python3.12/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] MPS memory logging failed: module 'torch.mps' has no attribute 'current_reserved_memory'\n",
      "[WARN] MPS memory logging failed: module 'torch.mps' has no attribute 'current_reserved_memory'\n",
      "[WARN] MPS memory logging failed: module 'torch.mps' has no attribute 'current_reserved_memory'\n",
      "[WARN] MPS memory logging failed: module 'torch.mps' has no attribute 'current_reserved_memory'\n",
      "[WARN] MPS memory logging failed: module 'torch.mps' has no attribute 'current_reserved_memory'\n",
      "TensorBoard log written to: runs/llm_monitor_20250611-144411\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "# === 1. Dummy LLM or load your own model === #\n",
    "class TinyTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size=1000, embed_dim=64):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=embed_dim, nhead=4), num_layers=2\n",
    "        )\n",
    "        self.fc = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.transformer(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = TinyTransformer().to(device)\n",
    "\n",
    "# === 2. TensorBoard Setup === #\n",
    "logdir = f\"runs/llm_monitor_{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "writer = SummaryWriter(logdir)\n",
    "\n",
    "# === 3. Hook to capture activations === #\n",
    "def activation_hook(name):\n",
    "    def hook(module, input, output):\n",
    "        if isinstance(output, torch.Tensor):\n",
    "            writer.add_scalar(f\"Activations/{name}_mean\", output.mean().item(), global_step)\n",
    "        elif isinstance(output, tuple):\n",
    "            for i, out in enumerate(output):\n",
    "                if isinstance(out, torch.Tensor):\n",
    "                    writer.add_scalar(f\"Activations/{name}_{i}_mean\", out.mean().item(), global_step)\n",
    "    return hook\n",
    "\n",
    "# === 4. Register hooks === #\n",
    "for name, module in model.named_modules():\n",
    "    if not isinstance(module, nn.Sequential):\n",
    "        module.register_forward_hook(activation_hook(name))\n",
    "\n",
    "# === 5. Dummy input & loop === #\n",
    "global_step = 0\n",
    "for step in range(5):\n",
    "    global_step = step\n",
    "    x = torch.randint(0, 1000, (10, 32)).to(device)  # (sequence_length, batch_size)\n",
    "    out = model(x)\n",
    "\n",
    "    # === 6. Log MPS Memory === #\n",
    "    try:\n",
    "        alloc = torch.mps.current_allocated_memory()\n",
    "        reserved = torch.mps.current_reserved_memory()\n",
    "        if alloc is not None:\n",
    "            writer.add_scalar(\"MPS/AllocatedMemory_MB\", alloc / (1024 ** 2), global_step)\n",
    "        if reserved is not None:\n",
    "            writer.add_scalar(\"MPS/ReservedMemory_MB\", reserved / (1024 ** 2), global_step)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] MPS memory logging failed: {e}\")\n",
    "\n",
    "writer.close()\n",
    "print(f\"TensorBoard log written to: {logdir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bb627b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
